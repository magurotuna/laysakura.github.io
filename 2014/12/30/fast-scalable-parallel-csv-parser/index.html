<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>速いしスケールする並列CSVパーサ作った紆余曲折話 | 俺とお前とlaysakura</title>
  <meta name="viewport" content="width=device-width">
  <meta name="description" content="年の瀬にどうしてもCSVを並列にパースしたくなって、PartialCsvParserというC++のライブラリを作った。  1スレッドでも高速だし複数スレッドで使うとちゃんとスケールする ヘッダファイルだけインクルードすればコンパイルなしで使える パブリックドメインなので自分のリポジトリに git add とかしてもおk  という3拍子揃ったやつです。 細かいことはプロジェクトのページを見ていただく">
<meta name="keywords" content="High Performance Computing">
<meta property="og:type" content="article">
<meta property="og:title" content="速いしスケールする並列CSVパーサ作った紆余曲折話">
<meta property="og:url" content="https://laysakura.github.io/2014/12/30/fast-scalable-parallel-csv-parser/index.html">
<meta property="og:site_name" content="俺とお前とlaysakura">
<meta property="og:description" content="年の瀬にどうしてもCSVを並列にパースしたくなって、PartialCsvParserというC++のライブラリを作った。  1スレッドでも高速だし複数スレッドで使うとちゃんとスケールする ヘッダファイルだけインクルードすればコンパイルなしで使える パブリックドメインなので自分のリポジトリに git add とかしてもおk  という3拍子揃ったやつです。 細かいことはプロジェクトのページを見ていただく">
<meta property="og:locale" content="ja">
<meta property="og:updated_time" content="2019-05-04T06:11:18.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="速いしスケールする並列CSVパーサ作った紆余曲折話">
<meta name="twitter:description" content="年の瀬にどうしてもCSVを並列にパースしたくなって、PartialCsvParserというC++のライブラリを作った。  1スレッドでも高速だし複数スレッドで使うとちゃんとスケールする ヘッダファイルだけインクルードすればコンパイルなしで使える パブリックドメインなので自分のリポジトリに git add とかしてもおk  という3拍子揃ったやつです。 細かいことはプロジェクトのページを見ていただく">
  
    <link rel="alternative" href="http://cloud.feedly.com/#subscription%2Ffeed%2Fhttps%3A%2F%2Flaysakura.github.io%2Fatom.xml" title="俺とお前とlaysakura" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22289437-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

</head>
</html>
<body>
  <div id="container">
    <div class="mobile-nav-panel">
	<i class="icon-reorder icon-large"></i>
</div>
<header id="header">
	<h1 class="blog-title">
		<a href="/">俺とお前とlaysakura</a>
	</h1>
	<nav class="nav">
		<ul>
			<li><a href="/archives">過去の投稿</a></li>
			<li><a id="nav-search-btn" class="nav-icon" title="Search"></a></li>
			<li><a href="http://cloud.feedly.com/#subscription%2Ffeed%2Fhttps%3A%2F%2Flaysakura.github.io%2Fatom.xml" id="nav-rss-link" class="nav-icon" title="RSS Feed"></a></li>
		</ul>
	</nav>
	<div id="search-form-wrap">
		<form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://laysakura.github.io"></form>
	</div>
</header>
    <div id="main">
      <article id="post-速いしスケールする並列CSVパーサ作った紆余曲折話" class="post">
	<footer class="entry-meta-header">
		<span class="meta-elements date">
			<a href="/2014/12/30/fast-scalable-parallel-csv-parser/" class="article-date">
  <time datetime="2014-12-30T11:30:44.000Z" itemprop="datePublished">2014-12-30</time>
</a>
		</span>
	</footer>
	
	<header class="entry-header">
		
  
    <h1 class="article-title entry-title" itemprop="name">
      速いしスケールする並列CSVパーサ作った紆余曲折話
    </h1>
  

	</header>
	<div class="entry-content">
		
    	<p>年の瀬にどうしてもCSVを並列にパースしたくなって、<a href="https://github.com/laysakura/PartialCsvParser" target="_blank" rel="noopener">PartialCsvParser</a>というC++のライブラリを作った。</p>
<ul>
<li>1スレッドでも高速だし複数スレッドで使うとちゃんとスケールする</li>
<li>ヘッダファイルだけインクルードすればコンパイルなしで使える</li>
<li>パブリックドメインなので自分のリポジトリに <code>git add</code> とかしてもおk</li>
</ul>
<p>という3拍子揃ったやつです。</p>
<p>細かいことはプロジェクトのページを見ていただくとして、ブログには頑張ってベンチマークとった話と、全然スケールしなかったのに2行追加しただけでグンと並列性能が上がった話を書く。</p>
<a id="more"></a>
<!-- toc -->
<ul>
<li><a href="#作る前の勝算">作る前の勝算</a></li>
<li><a href="#作ったらスケールしなかった">作ったらスケールしなかった</a></li>
<li><a href="#じゃあどうしたか">じゃあどうしたか</a></li>
<li><a href="#ベンチマークを頑張ってとった話">ベンチマークを頑張ってとった話</a><ul>
<li><a href="#google-spreadsheetはデータ集計に超便利">Google SpreadSheetはデータ集計に超便利</a></li>
<li><a href="#ディスクのパフォーマンス計測にはfiohttpsgithubcomaxboefioがよかった">ディスクのパフォーマンス計測には<a href="https://github.com/axboe/fio" target="_blank" rel="noopener">fio</a>がよかった</a></li>
</ul>
</li>
<li><a href="#まとめ">まとめ</a></li>
</ul>
<!-- tocstop -->
<h1><span id="作る前の勝算">作る前の勝算</span></h1><p>CSVの並列パーサライブラリって、ちゃんとスケールするものが割と簡単に作れると思って作り始めた。</p>
<p>例えば2並列にしたいなら、CSVファイルを前半と後半に2分割してあげて、それぞれのスレッドで別々にパースしてあげれば良いだけ。</p>
<p>なぜスケールさせられると思ったかというと、</p>
<ul>
<li>確かにCSVのパーズという(比較的)単純な処理は、ディスクIOが並列性能のボトルネックになりがち</li>
<li>とはいえこれからはSSDの時代だし、SSDなら並列読込はスケールするって色んなとこで見た気がする</li>
</ul>
<p>という感じ。</p>
<p>最初からHDDでの並列性能は無視して、SSDで戦おうと思ってた。</p>
<h1><span id="作ったらスケールしなかった">作ったらスケールしなかった</span></h1><p>バージョン 0.1.0 を作ってみてSSD環境でベンチマークを取ってみたら全然スケールしなかった。寝た。</p>
<p>起きて悔しくなったのでもう一度色々測定してみると、<br>CSVファイルがページキャッシュに乗っている時、つまりオンメモリな処理をしているときは割とちゃんとスケールすることが分かった。</p>
<p>となるとやっぱりSSDアクセスがボトルネックになっていそう。<br>少し頭を巡らせパーサの気持ちになって考えてみた。</p>
<p>そもそもPartialCsvParserは、パース対象のCSVファイルをどかんと丸ごと<code>mmap(2)</code>している。<br>で、複数のスレッドが同じタイミングで離れた領域(ページ)を触りに行く。</p>
<p>このとき、基本的には要求したページがまだメモリに乗っていなくてページフォルトを起こし、ディスクまで取りに行くことになるのだけど、複数のスレッドから同タイミングで「そこそこ離れているけどそんなに離れてはいない」ページを取りに行くことになる。</p>
<p>SSDの気持ちになるとこれはつらい。そもそもSSDが並列性能出るのって、SSDはフラッシュメモリ(板)の集合であって、別々の板のページを同時に要求されたら同時に返せるからってのが基本…なはず。</p>
<p>(SSDチップにもよるけど、)CSVファイルなんてものはサイズもたかが知れているし、同一の板にちょい離れたページを同タイミングで要求しているような気がして、そうするとSSDアクセスがボトルネックになっても仕方がないなという気持ちになった。</p>
<h1><span id="じゃあどうしたか">じゃあどうしたか</span></h1><p>やっぱり複数スレッドから同時にCSVなんて小さいファイルにアクセスしに行くのは大変だろうと思ったので、CSVファイルをドカンと1スレッドでメモリに乗せたくなった。</p>
<p>1スレッドでドカンとやると、ランダムアクセスじゃなくてシーケンシャルアクセスになる。<br>いくらランダムアクセスに強いと言われるSSDといえど、シーケンシャルアクセスのほうが1桁は速い。</p>
<p>とはいえ<code>mmap(2)</code>を捨てて<code>read(2)</code>使うのは、コーディング上面倒くさい。とても面倒くさい。</p>
<p><code>mmap(2)</code>でシーケンシャルに読みたい、つまりプリフェッチできないもんかなぁ。<br>と思って探したら<code>madvise(2)</code>が見つかった。</p>
<p><code>madvise(2)</code>はカーネルに「この領域はプリフェッチしておいてほしいなぁ(ﾁﾗｯﾁﾗｯ」となんとなーくお願いするためのシステムコール、らしい。</p>
<p>ダメ元で使ってみたプルリクエストがこちら。</p>
<p><a href="https://github.com/laysakura/PartialCsvParser/pull/12/files" target="_blank" rel="noopener">Prefetch pages by madvise(2) to prevent random accesses from threads. by laysakura · Pull Request #12 · laysakura/PartialCsvParser · GitHub</a></p>
<p>たった2行。コメント入れても3行。</p>
<p>これがうまくいって、グンとスケールするようになった。</p>
<p>結局のところ、まだスレッド作ってない段階でガツッとシーケンシャルアクセスしてメモリに乗せるので、<br>図らずもHDDでもちゃんとスケールするようになった。</p>
<h1><span id="ベンチマークを頑張ってとった話">ベンチマークを頑張ってとった話</span></h1><p>年末で実家にこもれたので、まとまった時間とってそこそこしっかりベンチマークをとれた。</p>
<p>どんな風にベンチマークとったかなどは、<a href="https://github.com/laysakura/PartialCsvParser/tree/master/benchmark" target="_blank" rel="noopener">ここ</a> にかなりしっかり書いた(つもり)。</p>
<p>ここではすぐに役立ちそうなことを2点ほど。</p>
<h2><span id="google-spreadsheetはデータ集計に超便利">Google SpreadSheetはデータ集計に超便利</span></h2><p>学生時代はExcelとかGnuplot (ｳｯｱﾀﾏｶﾞ) とか使ってベンチマーク結果を集計してたけど、会社でGoogle Drive使うこと増えてきたし、<br>試しにGoogle SpreadSheetでデータ集計してみた。</p>
<p>これが大当たりで、</p>
<ul>
<li>実験結果の集計に使うレベルならExcelと遜色なく使える</li>
<li>グラフウィザードがExcelよりなんとなく分かりやすい気がするし、デフォルトのデザインも悪くない</li>
<li>生データやグラフを簡単に公開できる。特にグラフは自動で画像ファイルにしてくれたりする</li>
</ul>
<p>と最高だった。</p>
<h2><span id="ディスクのパフォーマンス計測にはfioがよかった">ディスクのパフォーマンス計測にはがよかった</span></h2><p><code>hdparm</code>とか<code>bonnie++</code>とか、世の中には色々とディスクのベンチマークをとるためのツールが存在している。</p>
<p>そんな中で<a href="https://github.com/axboe/fio" target="_blank" rel="noopener">fio</a>はダントツで使いやすかった。<br>こんな感じで、短い設定ファイル作ってコマンドライン引数にそれだけ渡せば何かそれっぽい結果が出てくる。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ vim random-read-mem.fio</span><br><span class="line">[random-read]</span><br><span class="line">rw=randread</span><br><span class="line">size=512m</span><br><span class="line">directory=/dev/shm</span><br><span class="line"></span><br><span class="line">$ vim sequential-read-hdd.fio</span><br><span class="line">[sequential-read]</span><br><span class="line">rw=<span class="built_in">read</span></span><br><span class="line">size=512m</span><br><span class="line">directory=/dev/shm</span><br><span class="line"></span><br><span class="line">$ fio random-read-mem.fio</span><br></pre></td></tr></table></figure>
<p>root権限いらないのもポイント高い。</p>
<h1><span id="まとめ">まとめ</span></h1><p>2014年も終わろうとしてるのにCSVなんて使う人少ないでしょうけど、どうしてもCSVをパースしたくなったらPartialCsvParserのことを思い出してください。</p>

    
	</div>
	<footer class="entry-footer">
		<div class="entry-meta-footer">
			<span class="category">
				
			</span>
			<span class="tags">
				
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/High-Performance-Computing/">High Performance Computing</a></li></ul>

			</span>
		</div>
	</footer>
    
    <footer class="author-info clearfix">
      <img class="author-picture circle" src="https://www.gravatar.com/avatar/cb02a2b3f429b7c938d1fe2665e8e342">
      <div class="author-content right">
        <div class="author-caption">
          <span class="label">author</span>
          Sho Nakatani a.k.a. laysakura
        </div>
        <p class="author-description">
          東京大学大学院 情報理工学系研究科 電子情報学専攻 修士課程で並列分散処理・ストリーム処理・データベースを研究。<br>
          2014年4月に株式会社ディー・エヌ・エーにエンジニアスペシャリストとして入社し、ソーシャルゲームのサーバサイド共通基盤の開発に従事。<br>
          2016年8月より、オンライン証券会社<a href="https://folio-sec.com">株式会社FOLIO</a>に入社。バックエンドシステム開発・プロジェクトマネージメント・Engineering Managementに従事。<br>
        </p>
        <ul class="author-social-buttons">
          <li class="author-social-button"><a class="fa fa-lg fa-twitter-square" href="https://twitter.com/laysakura"></a></li>
          <li class="author-social-button"><a class="fa fa-lg fa-github-square" href="https://github.com/laysakura"></a></li>
          <li class="author-social-button"><a class="fa fa-lg fa-facebook-square" href="https://www.facebook.com/lay.sakura"></a></li>
        </ul>
      </div>
    </footer>
    
	
    
<nav id="article-nav">
  
    <a href="/2016/07/02/1cir6fvic10000wjiuq19loade/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          はてなブログからgithub.ioに移転しました
        
      </div>
    </a>
  
  
    <a href="/2014/02/18/mysqlite/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">
        
          MySQLite: SQLiteデータベースを読み書きするMySQLストレージエンジン
        
      </div>
    </a>
  
</nav>

  
</article>




<section id="comments">
  <div id="disqus_thread">

  <!-- comment service provided by disqus -->
  <script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
    var disqus_config = function () {
        this.page.url = https://laysakura.github.io/2014/12/30/fast-scalable-parallel-csv-parser/;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = https://laysakura.github.io/2014/12/30/fast-scalable-parallel-csv-parser/; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        
        s.src = '//laysakura.disqus.com/embed.js';
        
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>


    </div>
    <div class="mb-search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:laysakura.github.io">
  </form>
</div>
<footer id="footer">
	<h1 class="footer-blog-title">
		<a href="/">俺とお前とlaysakura</a>
	</h1>
	<span class="copyright">
		&copy; 2019 Sho Nakatani a.k.a. laysakura<br>
		Modify from <a href="http://sanographix.github.io/tumblr/apollo/" target="_blank">Apollo</a> theme, designed by <a href="http://www.sanographix.net/" target="_blank">SANOGRAPHIX.NET</a><br>
		Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	</span>
</footer>
    
<script>
  var disqus_shortname = 'laysakura';
  
  var disqus_url = 'https://laysakura.github.io/2014/12/30/fast-scalable-parallel-csv-parser/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//go.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
  </div>

  <!-- Go to www.addthis.com/dashboard to customize your tools -->
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-57791a9296b5772b"></script>

</body>
</html>
